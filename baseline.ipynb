{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kaggle api reference\n",
    "https://github.com/Kaggle/kaggle-api/blob/main/docs/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:06.441086Z",
     "start_time": "2024-11-09T08:09:05.944709Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from typing import TYPE_CHECKING, Optional, List, Dict, Any, Callable, Union, Tuple\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import dill\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:06.453879Z",
     "start_time": "2024-11-09T08:09:06.450679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pandas 2.2.3, polars 1.6.0, numpy 2.0.2, lightgbm 4.5.0, optuna 4.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"pandas {pd.__version__}, polars {pl.__version__}, numpy {np.__version__}, lightgbm {lgb.__version__}, optuna {optuna.__version__}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:06.595267Z",
     "start_time": "2024-11-09T08:09:06.549049Z"
    }
   },
   "outputs": [],
   "source": [
    "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "if not IS_KAGGLE: \n",
    "    os.chdir('./kaggle')\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "BASE_PATH = '/kaggle/input/jane-street-real-time-market-data-forecasting' if IS_KAGGLE else './data'\n",
    "MODEL_PATH = '/kaggle/working' if IS_KAGGLE else './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:06.610021Z",
     "start_time": "2024-11-09T08:09:06.608378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, './data', './models')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IS_KAGGLE, BASE_PATH, MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:06.669830Z",
     "start_time": "2024-11-09T08:09:06.662675Z"
    }
   },
   "outputs": [],
   "source": [
    "if TYPE_CHECKING:\n",
    "    from __main__ import Config, ModelConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:06.741937Z",
     "start_time": "2024-11-09T08:09:06.739508Z"
    }
   },
   "outputs": [],
   "source": [
    "def r2_metric(y_true, y_pred, weights=None):\n",
    "    \"\"\"Calculate weighted R2 score\"\"\"\n",
    "    y_true = y_true.ravel()\n",
    "    y_pred = y_pred.ravel()\n",
    "\n",
    "    # If weights is None, use uniform weights\n",
    "    if weights is None:\n",
    "        weights = np.ones_like(y_true)\n",
    "    else:\n",
    "        weights = weights.ravel()\n",
    "\n",
    "    numerator = np.sum(weights * (y_true - y_pred) ** 2)\n",
    "    denominator = np.sum(weights * (y_true ** 2))\n",
    "    r2_score = 1 - (numerator / denominator)\n",
    "    return 'r2', r2_score, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:06.791381Z",
     "start_time": "2024-11-09T08:09:06.785022Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "def versioned_function(version: str, description: str = \"\"):\n",
    "    \"\"\"Function versioning decorator\"\"\"\n",
    "    def decorator(func: Callable) -> Callable:\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return func(*args, **kwargs)\n",
    "        \n",
    "        wrapper.version = version\n",
    "        wrapper.description = description\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:06.869601Z",
     "start_time": "2024-11-09T08:09:06.864190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass XGBoostModel(BaseModel):\\n    def _register_custom_metrics(self):\\n        # XGBoost에서는 custom_metrics를 train 파라미터로 전달\\n        if self.config.custom_metrics:\\n            self.config.params[\\'custom_metric\\'] = list(self.config.custom_metrics.values())\\n    \\n    def fit(self, train_data: Tuple[np.ndarray, np.ndarray], \\n           val_data: Optional[Tuple[np.ndarray, np.ndarray]] = None):\\n        train_X, train_y = train_data\\n        train_set = xgb.DMatrix(train_X, train_y)\\n        \\n        val_set = None\\n        watchlist = [(train_set, \\'train\\')]\\n        if val_data is not None:\\n            val_X, val_y = val_data\\n            val_set = xgb.DMatrix(val_X, val_y)\\n            watchlist.append((val_set, \\'valid\\'))\\n        \\n        self.model = xgb.train(\\n            self.config.params,\\n            train_set,\\n            evals=watchlist\\n        )\\n    \\n    def predict(self, X: np.ndarray) -> np.ndarray:\\n        return self.model.predict(xgb.DMatrix(X))\\n\\nclass NeuralNetworkModel(BaseModel):\\n    def _register_custom_metrics(self):\\n        # PyTorch/TensorFlow에서는 metrics를 모델 컴파일 시 등록\\n        self.metrics = list(self.config.custom_metrics.values())\\n    \\n    def fit(self, train_data: Tuple[np.ndarray, np.ndarray], \\n           val_data: Optional[Tuple[np.ndarray, np.ndarray]] = None):\\n        train_X, train_y = train_data\\n        \\n        # PyTorch example\\n        self.model = torch.nn.Sequential(\\n            torch.nn.Linear(train_X.shape[1], 64),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(64, 1)\\n        )\\n        \\n        optimizer = torch.optim.Adam(self.model.parameters(), \\n                                   lr=self.config.params.get(\\'learning_rate\\', 0.001))\\n        \\n        # Training loop with custom metrics\\n        for epoch in range(self.config.params.get(\\'epochs\\', 10)):\\n            self.model.train()\\n            # ... training implementation ...\\n            \\n            if val_data is not None:\\n                self.model.eval()\\n                # ... validation implementation ...\\n    \\n    def predict(self, X: np.ndarray) -> np.ndarray:\\n        self.model.eval()\\n        with torch.no_grad():\\n            X_tensor = torch.FloatTensor(X)\\n            return self.model(X_tensor).numpy()\\n\\nclass EnsembleModel(BaseModel):\\n    def __init__(self, config: \"ModelConfig\", models: List[BaseModel]):\\n        super().__init__(config)\\n        self.models = models\\n    \\n    def _register_custom_metrics(self):\\n        # 각 모델의 custom metrics는 이미 등록되어 있음\\n        pass\\n    \\n    def fit(self, train_data: Tuple[np.ndarray, np.ndarray], \\n           val_data: Optional[Tuple[np.ndarray, np.ndarray]] = None):\\n        for model in self.models:\\n            model.fit(train_data, val_data)\\n    \\n    def predict(self, X: np.ndarray) -> np.ndarray:\\n        predictions = [model.predict(X) for model in self.models]\\n        # Weighted average if weights are specified in config\\n        weights = self.config.params.get(\\'weights\\', None)\\n        if weights is not None:\\n            return np.average(predictions, axis=0, weights=weights)\\n        return np.mean(predictions, axis=0)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BaseModel:\n",
    "    \"\"\"Base model class for easy extension\"\"\"\n",
    "    def __init__(self, config: \"ModelConfig\"):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self._register_custom_metrics()\n",
    "    \n",
    "    def _register_custom_metrics(self):\n",
    "        \"\"\"Register custom metrics if needed\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def fit(self, train_data: Tuple[np.ndarray, np.ndarray], \n",
    "           val_data: Optional[Tuple[np.ndarray, np.ndarray]] = None):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def save(self, path: str):\n",
    "        with open(path, 'wb') as f:\n",
    "            dill.dump(self.model, f)\n",
    "    \n",
    "    def load(self, path: str):\n",
    "        with open(path, 'rb') as f:\n",
    "            self.model = dill.load(f)\n",
    "\n",
    "class LightGBMModel(BaseModel):\n",
    "    def _register_custom_metrics(self):\n",
    "        \"\"\"Register custom metrics for LightGBM\"\"\"\n",
    "        # Instead of registering metrics directly, we'll add them to params\n",
    "        if self.config.custom_metrics:\n",
    "            self.config.params['metric'] = list(self.config.custom_metrics.keys())\n",
    "    \n",
    "    def fit(self, train_data: Tuple[np.ndarray, np.ndarray, np.ndarray], \n",
    "           val_data: Optional[Tuple[np.ndarray, np.ndarray, np.ndarray]] = None):\n",
    "        train_X, train_y, train_w = train_data\n",
    "        train_set = lgb.Dataset(train_X, train_y, weight=train_w, free_raw_data=False)\n",
    "        \n",
    "        val_set = None\n",
    "        if val_data is not None:\n",
    "            val_X, val_y, val_w = val_data\n",
    "            val_set = lgb.Dataset(val_X, val_y, weight=val_w, free_raw_data=False)\n",
    "        \n",
    "        callbacks = [\n",
    "            lgb.early_stopping(stopping_rounds=100),\n",
    "            lgb.log_evaluation(period=100)\n",
    "        ]\n",
    "        \n",
    "        self.model = lgb.train(\n",
    "            self.config.params,\n",
    "            train_set,\n",
    "            num_boost_round=1000,\n",
    "            valid_sets=[val_set] if val_set else None,\n",
    "            valid_names=['valid'] if val_set else None,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# Example model implementations\n",
    "\"\"\"\n",
    "class XGBoostModel(BaseModel):\n",
    "    def _register_custom_metrics(self):\n",
    "        # XGBoost에서는 custom_metrics를 train 파라미터로 전달\n",
    "        if self.config.custom_metrics:\n",
    "            self.config.params['custom_metric'] = list(self.config.custom_metrics.values())\n",
    "    \n",
    "    def fit(self, train_data: Tuple[np.ndarray, np.ndarray], \n",
    "           val_data: Optional[Tuple[np.ndarray, np.ndarray]] = None):\n",
    "        train_X, train_y = train_data\n",
    "        train_set = xgb.DMatrix(train_X, train_y)\n",
    "        \n",
    "        val_set = None\n",
    "        watchlist = [(train_set, 'train')]\n",
    "        if val_data is not None:\n",
    "            val_X, val_y = val_data\n",
    "            val_set = xgb.DMatrix(val_X, val_y)\n",
    "            watchlist.append((val_set, 'valid'))\n",
    "        \n",
    "        self.model = xgb.train(\n",
    "            self.config.params,\n",
    "            train_set,\n",
    "            evals=watchlist\n",
    "        )\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return self.model.predict(xgb.DMatrix(X))\n",
    "\n",
    "class NeuralNetworkModel(BaseModel):\n",
    "    def _register_custom_metrics(self):\n",
    "        # PyTorch/TensorFlow에서는 metrics를 모델 컴파일 시 등록\n",
    "        self.metrics = list(self.config.custom_metrics.values())\n",
    "    \n",
    "    def fit(self, train_data: Tuple[np.ndarray, np.ndarray], \n",
    "           val_data: Optional[Tuple[np.ndarray, np.ndarray]] = None):\n",
    "        train_X, train_y = train_data\n",
    "        \n",
    "        # PyTorch example\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(train_X.shape[1], 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), \n",
    "                                   lr=self.config.params.get('learning_rate', 0.001))\n",
    "        \n",
    "        # Training loop with custom metrics\n",
    "        for epoch in range(self.config.params.get('epochs', 10)):\n",
    "            self.model.train()\n",
    "            # ... training implementation ...\n",
    "            \n",
    "            if val_data is not None:\n",
    "                self.model.eval()\n",
    "                # ... validation implementation ...\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.FloatTensor(X)\n",
    "            return self.model(X_tensor).numpy()\n",
    "\n",
    "class EnsembleModel(BaseModel):\n",
    "    def __init__(self, config: \"ModelConfig\", models: List[BaseModel]):\n",
    "        super().__init__(config)\n",
    "        self.models = models\n",
    "    \n",
    "    def _register_custom_metrics(self):\n",
    "        # 각 모델의 custom metrics는 이미 등록되어 있음\n",
    "        pass\n",
    "    \n",
    "    def fit(self, train_data: Tuple[np.ndarray, np.ndarray], \n",
    "           val_data: Optional[Tuple[np.ndarray, np.ndarray]] = None):\n",
    "        for model in self.models:\n",
    "            model.fit(train_data, val_data)\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        predictions = [model.predict(X) for model in self.models]\n",
    "        # Weighted average if weights are specified in config\n",
    "        weights = self.config.params.get('weights', None)\n",
    "        if weights is not None:\n",
    "            return np.average(predictions, axis=0, weights=weights)\n",
    "        return np.mean(predictions, axis=0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:06.928499Z",
     "start_time": "2024-11-09T08:09:06.923585Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self, config: \"Config\"):\n",
    "        self.config = config\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.features = None\n",
    "        self.preprocessor = None\n",
    "        self.feature_generator = None\n",
    "    \n",
    "    def load_data(self) -> Tuple[pl.DataFrame, Optional[pl.DataFrame]]:\n",
    "        \"\"\"Load train and test data\"\"\"\n",
    "        try:\n",
    "            if hasattr(self.config, 'partition_range') and self.config.partition_range is not None:\n",
    "                # Load specific partitions\n",
    "                train_parts = []\n",
    "                for i in self.config.partition_range:\n",
    "                    part_df = pl.read_parquet(\n",
    "                        f\"{BASE_PATH}/train.parquet/partition_id={i}/part-0.parquet\"\n",
    "                    )\n",
    "                    train_parts.append(part_df)\n",
    "                self.train_data = pl.concat(train_parts, how='vertical')\n",
    "            else:\n",
    "                # Load full dataset\n",
    "                self.train_data = pl.read_parquet(f\"{BASE_PATH}/train.parquet\")\n",
    "            \n",
    "            self.test_data = pl.read_parquet(f\"{BASE_PATH}/test.parquet\")\n",
    "            return self.train_data, self.test_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            self.train_data = None\n",
    "            self.test_data = None\n",
    "            return self.train_data, self.test_data\n",
    "        \n",
    "    def prepare_data(self, preprocessor: Optional[Callable] = None, \n",
    "                    feature_generator: Optional[Callable] = None,\n",
    "                    is_inference: bool = False) -> Tuple[pl.DataFrame, pl.DataFrame]:\n",
    "        \"\"\"Prepare data with custom preprocessing and feature generation\"\"\"\n",
    "        self.preprocessor = preprocessor\n",
    "        self.feature_generator = feature_generator\n",
    "        \n",
    "        # Process both train and test data with preprocessor only\n",
    "        if self.preprocessor:\n",
    "            self.train_data = self.preprocessor(self.train_data)\n",
    "            if self.test_data is not None:\n",
    "                self.test_data = self.preprocessor(self.test_data)\n",
    "        \n",
    "        # Feature generation will be done separately for each fold\n",
    "        # Only generate features for full dataset during inference\n",
    "        if is_inference and self.feature_generator:\n",
    "            self.train_data = self.feature_generator(self.train_data)\n",
    "            if self.test_data is not None:\n",
    "                self.test_data = self.feature_generator(self.test_data)\n",
    "            self.features = [col for col in self.train_data.columns\n",
    "                            if col.startswith('feature_')]\n",
    "\n",
    "        return self.train_data, self.test_data\n",
    "    \n",
    "    def generate_features(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"Generate features for a specific DataFrame\"\"\"\n",
    "        if self.feature_generator:\n",
    "            df = self.feature_generator(df)\n",
    "            self.features = [col for col in df.columns\n",
    "                            if col.startswith('feature_')]\n",
    "            return df\n",
    "        return df\n",
    "    \n",
    "    def get_feature_data(self, df: pl.DataFrame) -> Tuple[np.ndarray, Optional[np.ndarray], Optional[np.ndarray]]:\n",
    "        \"\"\"Extract features, target, and weights\"\"\"\n",
    "        missing_features = [f for f in self.features if f not in df.columns]\n",
    "        if missing_features:\n",
    "            raise ValueError(f\"Missing features in input data: {missing_features}\")\n",
    "\n",
    "        X = df.select(self.features).to_numpy()\n",
    "        y = df.select('responder_6').to_numpy() if 'responder_6' in df.columns else None\n",
    "        w = df.select('weight').to_numpy() if 'weight' in df.columns else None\n",
    "\n",
    "        return X, y, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:06.971009Z",
     "start_time": "2024-11-09T08:09:06.954912Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class SplitStrategy(ABC):\n",
    "    \"\"\"Base class for split strategies\"\"\"\n",
    "    def __init__(self, test_ratio: float = 0.2):\n",
    "        self.test_ratio = test_ratio\n",
    "    \n",
    "    def get_holdout_test(self, data: pl.DataFrame) -> Tuple[pl.DataFrame, pl.DataFrame]:\n",
    "        \"\"\"Split out final holdout test set using date_id\"\"\"\n",
    "        unique_dates = data['date_id'].unique().sort()\n",
    "        split_idx = int(len(unique_dates) * (1 - self.test_ratio))\n",
    "        split_date = unique_dates[split_idx]\n",
    "        \n",
    "        train_data = data.filter(pl.col('date_id') <= split_date)\n",
    "        test_data = data.filter(pl.col('date_id') > split_date)\n",
    "        \n",
    "        print(\"\\nHoldout Test Split Info:\")\n",
    "        print(f\"Total unique dates: {len(unique_dates)}\")\n",
    "        print(f\"Train dates range: {unique_dates[0]} - {unique_dates[split_idx]}\")\n",
    "        print(f\"Test dates range: {unique_dates[split_idx + 1]} - {unique_dates[-1]}\")\n",
    "        print(f\"Train samples: {len(train_data):,}, Test samples: {len(test_data):,}\")\n",
    "        \n",
    "        return train_data, test_data\n",
    "    \n",
    "    @abstractmethod\n",
    "    def split(self, data: pl.DataFrame) -> List[Tuple[pl.DataFrame, pl.DataFrame]]:\n",
    "        \"\"\"Split remaining data into train/val sets for cross validation\n",
    "        Returns:\n",
    "            List of (train, val) DataFrame tuples\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class TimeBasedSplit(SplitStrategy):\n",
    "    def __init__(self, train_ratio: float = 0.75, test_ratio: float = 0.2):\n",
    "        super().__init__(test_ratio)\n",
    "        self.train_ratio = train_ratio\n",
    "    \n",
    "    def split(self, data: pl.DataFrame) -> List[Tuple[pl.DataFrame, pl.DataFrame]]:\n",
    "        \"\"\"Single split based on date_id\"\"\"\n",
    "        unique_dates = data['date_id'].unique().sort()\n",
    "        split_idx = int(len(unique_dates) * self.train_ratio)\n",
    "        split_date = unique_dates[split_idx]\n",
    "        \n",
    "        train = data.filter(pl.col('date_id') <= split_date)\n",
    "        val = data.filter(pl.col('date_id') > split_date)\n",
    "        \n",
    "        print(\"\\nTime Based Split Info:\")\n",
    "        print(f\"Train dates range: {unique_dates[0]} - {unique_dates[split_idx]}\")\n",
    "        print(f\"Val dates range: {unique_dates[split_idx + 1]} - {unique_dates[-1]}\")\n",
    "        print(f\"Train samples: {len(train):,}, Val samples: {len(val):,}\")\n",
    "        \n",
    "        return [(train, val)]\n",
    "\n",
    "class TimeSeriesKFold(SplitStrategy):\n",
    "    def __init__(self, n_splits: int = 5, test_ratio: float = 0.2):\n",
    "        super().__init__(test_ratio)\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def split(self, data: pl.DataFrame) -> List[Tuple[pl.DataFrame, pl.DataFrame]]:\n",
    "        \"\"\"Multiple splits based on date_id\"\"\"\n",
    "        unique_dates = data['date_id'].unique().sort()\n",
    "        splits = []\n",
    "        \n",
    "        # Calculate initial training size and increment\n",
    "        initial_train_size = len(unique_dates) // (self.n_splits + 1)\n",
    "        remaining_dates = len(unique_dates) - initial_train_size\n",
    "        val_size = remaining_dates // self.n_splits\n",
    "        \n",
    "        print(f\"\\nTime Series {self.n_splits}-Fold Split Info:\")\n",
    "        print(f\"Total unique dates: {len(unique_dates)}\")\n",
    "        print(f\"Initial train size: {initial_train_size} dates\")\n",
    "        print(f\"Validation size: ~{val_size} dates per fold\")\n",
    "        \n",
    "        for i in range(self.n_splits):\n",
    "            train_end_idx = initial_train_size + (i * val_size)\n",
    "            val_end_idx = train_end_idx + val_size\n",
    "            if i == self.n_splits - 1:  # Last fold uses all remaining dates\n",
    "                val_end_idx = len(unique_dates)\n",
    "            \n",
    "            train_dates = unique_dates[:train_end_idx]\n",
    "            val_dates = unique_dates[train_end_idx:val_end_idx]\n",
    "            \n",
    "            train = data.filter(pl.col('date_id').is_in(train_dates))\n",
    "            val = data.filter(pl.col('date_id').is_in(val_dates))\n",
    "            \n",
    "            print(f\"\\nFold {i+1}:\")\n",
    "            print(f\"Train dates range: {train_dates[0]} - {train_dates[-1]}\")\n",
    "            print(f\"Val dates range: {val_dates[0]} - {val_dates[-1]}\")\n",
    "            print(f\"Train samples: {len(train):,}, Val samples: {len(val):,}\")\n",
    "            \n",
    "            splits.append((train, val))\n",
    "        \n",
    "        return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Handler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:07.019396Z",
     "start_time": "2024-11-09T08:09:07.007541Z"
    }
   },
   "outputs": [],
   "source": [
    "class OptimizationHandler:\n",
    "    def __init__(self, config: \"Config\", model_class: type):\n",
    "        self.config = config\n",
    "        self.model_class = model_class\n",
    "    \n",
    "    def get_search_space(self, trial: optuna.Trial) -> Dict[str, Any]:\n",
    "        \"\"\"Define search space for each model type\"\"\"\n",
    "        if self.config.model.name == 'lightgbm':\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 16, 96),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "                'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "                'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "                'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "            }\n",
    "        \"\"\"\n",
    "        elif self.config.model.name == 'xgboost':\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n",
    "                'lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n",
    "            }\n",
    "        \"\"\"\n",
    "        return {}\n",
    "    \n",
    "    def objective(self, trial: optuna.Trial, train_data: Tuple[np.ndarray, np.ndarray], \n",
    "                 val_data: Tuple[np.ndarray, np.ndarray]) -> float:\n",
    "        \"\"\"Optimization objective\"\"\"\n",
    "        params = self.get_search_space(trial)\n",
    "        self.config.model.params.update(params)\n",
    "        \n",
    "        model = self.model_class(self.config.model)\n",
    "        model.fit(train_data, val_data)\n",
    "        \n",
    "        val_X, val_y = val_data\n",
    "        predictions = model.predict(val_X)\n",
    "        \n",
    "        return np.mean((predictions - val_y) ** 2) ** 0.5\n",
    "    \n",
    "    def optimize(self, train_data: Tuple[np.ndarray, np.ndarray], \n",
    "                val_data: Tuple[np.ndarray, np.ndarray], n_trials: int = 100) -> Dict[str, Any]:\n",
    "        \"\"\"Run optimization\"\"\"\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        objective = lambda trial: self.objective(trial, train_data, val_data)\n",
    "        study.optimize(objective, n_trials=n_trials)\n",
    "        \n",
    "        print(f\"Best score: {study.best_value:.4f}\")\n",
    "        print(\"Best params:\", study.best_params)\n",
    "        \n",
    "        return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Handler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:07.070258Z",
     "start_time": "2024-11-09T08:09:07.059007Z"
    }
   },
   "outputs": [],
   "source": [
    "class KaggleHandler:\n",
    "    def __init__(self, config: \"Config\"):\n",
    "        self.config = config\n",
    "        self.api = KaggleApi()\n",
    "        self.api.authenticate()\n",
    "    \n",
    "    def upload_pipeline(self, pipeline: Any, dataset_title: Optional[str] = None):\n",
    "        \"\"\"Upload pipeline to Kaggle dataset\"\"\"\n",
    "        if IS_KAGGLE:\n",
    "            raise ValueError(\"This function is for local environment only\")\n",
    "        \n",
    "        tmp_dir = \"./kaggle_upload\"\n",
    "        os.makedirs(tmp_dir, exist_ok=True)\n",
    "        \n",
    "        filename = f\"{self.config.dataset_name.split('/')[-1]}.pkl\"\n",
    "        pipeline_path = os.path.join(tmp_dir, filename)\n",
    "        \n",
    "        original_path = pipeline.config.model_path\n",
    "        pipeline.config.model_path = os.path.join(os.path.dirname(original_path), filename)\n",
    "        \n",
    "        pipeline.save()\n",
    "        \n",
    "        import shutil\n",
    "        shutil.copy2(pipeline.config.model_path, pipeline_path)\n",
    "        \n",
    "        metadata = {\n",
    "            \"title\": dataset_title or self.config.dataset_name.split('/')[-1],\n",
    "            \"id\": f\"{self.config.dataset_name}\",\n",
    "            \"licenses\": [{\"name\": \"CC0-1.0\"}]\n",
    "        }\n",
    "        \n",
    "        import json\n",
    "        with open(os.path.join(tmp_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "            json.dump(metadata, f)\n",
    "        \n",
    "        try:\n",
    "            print(f\"Creating new dataset: {self.config.dataset_name}\")\n",
    "            self.api.dataset_create_new(\n",
    "                folder=tmp_dir,\n",
    "                public=False, # For private datasets\n",
    "                quiet=False\n",
    "            )\n",
    "            print(\"Dataset created successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating Kaggle dataset: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:07.149168Z",
     "start_time": "2024-11-09T08:09:07.119845Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "class Pipeline:\n",
    "    def __init__(self, config: \"Config\"):\n",
    "        self.config = config\n",
    "        self.data_handler = DataHandler(config)\n",
    "        self.model = self._get_model()\n",
    "        self.kaggle_handler = KaggleHandler(config) if not IS_KAGGLE else None\n",
    "    \n",
    "    def _get_model(self) -> BaseModel:\n",
    "        \"\"\"Get model instance based on config\"\"\"\n",
    "        model_map = {\n",
    "            'lightgbm': LightGBMModel,\n",
    "            # 'xgboost': XGBoostModel,\n",
    "            # 'neural_network': NeuralNetworkModel,\n",
    "        }\n",
    "        model_class = model_map.get(self.config.model.name)\n",
    "        if model_class is None:\n",
    "            raise ValueError(f\"Unknown model: {self.config.model.name}\")\n",
    "        return model_class(self.config.model)\n",
    "    \n",
    "    def train(self, preprocessor: Optional[Callable] = None, \n",
    "            feature_generator: Optional[Callable] = None,\n",
    "            optimize: bool = False,\n",
    "            n_trials: int = 100) -> pl.DataFrame:\n",
    "        \"\"\"Train pipeline and return holdout test set\"\"\"\n",
    "        # Load and prepare data\n",
    "        print(\"Loading and preparing data...\")\n",
    "        self.data_handler.load_data()\n",
    "        self.data_handler.prepare_data(preprocessor, feature_generator, is_inference=False)\n",
    "        \n",
    "        # Split data using configured strategy\n",
    "        print(\"Splitting data using configured strategy...\")\n",
    "        train_data_full, holdout_test = self.config.split_strategy.get_holdout_test(self.data_handler.train_data)\n",
    "        splits = self.config.split_strategy.split(train_data_full)\n",
    "        \n",
    "        # Clear memory after splitting\n",
    "        del train_data_full\n",
    "        gc.collect()\n",
    "        \n",
    "        best_model = None\n",
    "        best_score = float('-inf')\n",
    "        \n",
    "        # Train and validate on each split\n",
    "        for i, (train_df, val_df) in enumerate(splits):\n",
    "            print(f\"\\nTraining fold {i+1}/{len(splits)}\")\n",
    "           \n",
    "            # Generate features for this fold's train and validation data\n",
    "            train_df_with_features = self.data_handler.generate_features(train_df)\n",
    "            val_df_with_features = self.data_handler.generate_features(val_df)\n",
    "            \n",
    "            # Clear original dataframes\n",
    "            del train_df, val_df\n",
    "            gc.collect() \n",
    "\n",
    "            train_data = self.data_handler.get_feature_data(train_df_with_features)\n",
    "            val_data = self.data_handler.get_feature_data(val_df_with_features)\n",
    "\n",
    "            # Clear feature dataframes\n",
    "            del train_df_with_features, val_df_with_features\n",
    "            gc.collect()\n",
    "\n",
    "            # Create new model instance for each fold\n",
    "            fold_model = self._get_model()\n",
    "\n",
    "            # Optionally run optimization (only on first fold)\n",
    "            if optimize and i == 0:\n",
    "                print(\"Running hyperparameter optimization...\")\n",
    "                optimizer = OptimizationHandler(self.config, type(fold_model))\n",
    "                best_params = optimizer.optimize(train_data, val_data, n_trials)\n",
    "                self.config.model.params.update(best_params)\n",
    "                # Recreate model with optimized parameters\n",
    "                del fold_model\n",
    "                gc.collect()\n",
    "                fold_model = self._get_model()\n",
    "            \n",
    "            # Train model\n",
    "            print(\"Training model...\")\n",
    "            fold_model.fit(train_data, val_data)\n",
    "            \n",
    "            # Evaluate on validation set using R2\n",
    "            val_X, val_y, val_w = val_data\n",
    "            val_pred = fold_model.predict(val_X)\n",
    "            _, val_score, _ = r2_metric(val_y, val_pred, val_w)\n",
    "            print(f\"Validation R2 score for fold {i+1}: {val_score:.4f}\")\n",
    "            \n",
    "            # Keep track of best model\n",
    "            if val_score > best_score:\n",
    "                best_score = val_score\n",
    "                if best_model is not None:\n",
    "                    del best_model\n",
    "                    gc.collect()\n",
    "                best_model = fold_model\n",
    "            else:\n",
    "                del fold_model\n",
    "                gc.collect()\n",
    "\n",
    "            # Clear fold data\n",
    "            del train_data, val_data, val_X, val_y, val_w, val_pred\n",
    "            gc.collect()\n",
    "        \n",
    "        # Use best model for final predictions\n",
    "        self.model = best_model\n",
    "        print(f\"\\nBest validation score: {best_score:.4f}\")\n",
    "        \n",
    "        # Save pipeline\n",
    "        print(\"\\nSaving pipeline...\")\n",
    "        self.save()\n",
    "\n",
    "        # After finding best model, generate features for holdout test\n",
    "        if holdout_test is not None:\n",
    "            holdout_test = self.data_handler.generate_features(holdout_test)\n",
    "        \n",
    "        # For inference, generate features for full dataset\n",
    "        self.data_handler.prepare_data(preprocessor, feature_generator, is_inference=True)\n",
    "        \n",
    "        # Clear any remaining memory\n",
    "        gc.collect()\n",
    "\n",
    "        return holdout_test\n",
    "\n",
    "    def predict(self, df: pl.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        print(\"Starting prediction...\")\n",
    "        print(f\"Input DataFrame shape: {df.shape}\")\n",
    "        print(f\"Available features: {self.data_handler.features}\")\n",
    "\n",
    "        X, _, _ = self.data_handler.get_feature_data(df)\n",
    "        print(f\"Extracted feature matrix shape: {X.shape}\")\n",
    "\n",
    "        predictions = self.model.predict(X)\n",
    "\n",
    "        print(f\"Predictions shape: {predictions.shape}\")\n",
    "        return predictions\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"Save pipeline with detailed logging and version tracking\"\"\"\n",
    "        os.makedirs(os.path.dirname(self.config.model_path), exist_ok=True)\n",
    "        \n",
    "        # Verify model state\n",
    "        if not hasattr(self.model, 'config') or not hasattr(self.model, 'model'):\n",
    "            raise ValueError(\"Model appears to be uninitialized or invalid\")\n",
    "        \n",
    "        # Create detailed config dictionary\n",
    "        config_dict = {\n",
    "            'model': {\n",
    "                'name': self.config.model.name,\n",
    "                'params': dict(self.config.model.params),\n",
    "                'custom_metrics': {k: v.__name__ for k, v in self.config.model.custom_metrics.items()}\n",
    "            },\n",
    "            'paths': {\n",
    "                'model_path': self.config.model_path,\n",
    "                'dataset_name': self.config.dataset_name\n",
    "            },\n",
    "            'split_strategy': {\n",
    "                'type': type(self.config.split_strategy).__name__,\n",
    "                'params': {\n",
    "                    'test_ratio': self.config.split_strategy.test_ratio,\n",
    "                    **(({'train_ratio': self.config.split_strategy.train_ratio} \n",
    "                        if isinstance(self.config.split_strategy, TimeBasedSplit) else\n",
    "                        {'n_splits': self.config.split_strategy.n_splits}))\n",
    "                }\n",
    "            },\n",
    "            'seed': self.config.seed\n",
    "        }\n",
    "        \n",
    "        # Create pipeline metadata with version information\n",
    "        pipeline_data = {\n",
    "            'model': self.model,\n",
    "            'config': config_dict,\n",
    "            'data_handler': {\n",
    "                'preprocessor': self.data_handler.preprocessor,\n",
    "                'preprocessor_version': getattr(self.data_handler.preprocessor, 'version', 'unknown'),\n",
    "                'preprocessor_description': getattr(self.data_handler.preprocessor, 'description', ''),\n",
    "                'feature_generator': self.data_handler.feature_generator,\n",
    "                'feature_generator_version': getattr(self.data_handler.feature_generator, 'version', 'unknown'),\n",
    "                'feature_generator_description': getattr(self.data_handler.feature_generator, 'description', ''),\n",
    "                'features': self.data_handler.features,\n",
    "                'n_features': len(self.data_handler.features)\n",
    "            },\n",
    "            'version': '1.0',\n",
    "            'timestamp': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        # Print pipeline information\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Pipeline Information:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        print(f\"\\n1. Model Configuration:\")\n",
    "        print(f\"   - Model Type: {config_dict['model']['name']}\")\n",
    "        print(f\"   - Number of Features: {len(self.data_handler.features)}\")\n",
    "        print(f\"   - Model Parameters:\")\n",
    "        for k, v in config_dict['model']['params'].items():\n",
    "            print(f\"     * {k}: {v}\")\n",
    "        \n",
    "        print(f\"\\n2. Data Processing:\")\n",
    "        print(f\"   - Preprocessor: {self.data_handler.preprocessor.__name__ if self.data_handler.preprocessor else 'None'}\")\n",
    "        print(f\"     * Version: {getattr(self.data_handler.preprocessor, 'version', 'unknown')}\")\n",
    "        print(f\"     * Description: {getattr(self.data_handler.preprocessor, 'description', '')}\")\n",
    "        print(f\"   - Feature Generator: {self.data_handler.feature_generator.__name__ if self.data_handler.feature_generator else 'None'}\")\n",
    "        print(f\"     * Version: {getattr(self.data_handler.feature_generator, 'version', 'unknown')}\")\n",
    "        print(f\"     * Description: {getattr(self.data_handler.feature_generator, 'description', '')}\")\n",
    "        print(f\"   - First 5 Features: {self.data_handler.features[:5]}\")\n",
    "        \n",
    "        print(f\"\\n3. Split Strategy:\")\n",
    "        print(f\"   - Type: {config_dict['split_strategy']['type']}\")\n",
    "        for k, v in config_dict['split_strategy']['params'].items():\n",
    "            print(f\"   - {k}: {v}\")\n",
    "        \n",
    "        print(f\"\\n4. Save Location:\")\n",
    "        print(f\"   - Path: {self.config.model_path}\")\n",
    "        print(f\"   - Dataset Name: {self.config.dataset_name}\")\n",
    "        print(f\"   - Timestamp: {pipeline_data['timestamp']}\")\n",
    "        \n",
    "        try:\n",
    "            with open(self.config.model_path, 'wb') as f:\n",
    "                dill.dump(pipeline_data, f)\n",
    "            print(\"\\nPipeline saved successfully! ✓\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError saving pipeline: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def load(self, path: Optional[str] = None):\n",
    "        \"\"\"Load pipeline with extensive validation and version tracking\"\"\"\n",
    "        load_path = path if path is not None else self.config.model_path\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Loading Pipeline:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        try:\n",
    "            with open(load_path, 'rb') as f:\n",
    "                pipeline_data = dill.load(f)\n",
    "            \n",
    "            # Phase 1: Structure Validation\n",
    "            print(\"\\nPhase 1: Structure Validation\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            required_components = ['model', 'config', 'data_handler', 'version']\n",
    "            missing = [comp for comp in required_components if comp not in pipeline_data]\n",
    "            if missing:\n",
    "                raise ValueError(f\"Missing required components in pipeline: {missing}\")\n",
    "            print(\"✓ Basic structure validation passed\")\n",
    "            \n",
    "            required_data_handler = ['preprocessor', 'feature_generator', 'features', 'n_features',\n",
    "                                'preprocessor_version', 'feature_generator_version']\n",
    "            missing_dh = [comp for comp in required_data_handler if comp not in pipeline_data['data_handler']]\n",
    "            if missing_dh:\n",
    "                raise ValueError(f\"Missing data handler components: {missing_dh}\")\n",
    "            print(\"✓ Data handler structure validation passed\")\n",
    "            \n",
    "            # Phase 2: Model Validation\n",
    "            print(\"\\nPhase 2: Model Validation\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            self.model = pipeline_data['model']\n",
    "            config_dict = pipeline_data['config']\n",
    "            \n",
    "            required_model_attrs = ['predict', 'model', 'config']\n",
    "            missing_attrs = [attr for attr in required_model_attrs if not hasattr(self.model, attr)]\n",
    "            if missing_attrs:\n",
    "                raise AttributeError(f\"Model missing required attributes: {missing_attrs}\")\n",
    "            print(\"✓ Model attributes validation passed\")\n",
    "            \n",
    "            # Test model with dummy data\n",
    "            try:\n",
    "                n_features = len(pipeline_data['data_handler']['features'])\n",
    "                dummy_input = np.random.random((5, n_features))\n",
    "                dummy_pred = self.model.predict(dummy_input)\n",
    "                if not isinstance(dummy_pred, np.ndarray):\n",
    "                    raise TypeError(f\"Model prediction returned {type(dummy_pred)}, expected numpy.ndarray\")\n",
    "                if len(dummy_pred.shape) != 1 or len(dummy_pred) != 5:\n",
    "                    raise ValueError(f\"Unexpected prediction shape: {dummy_pred.shape}, expected (5,)\")\n",
    "                print(\"✓ Model prediction test passed\")\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Model prediction test failed: {str(e)}\")\n",
    "            \n",
    "            # Phase 3: Function Version Validation\n",
    "            print(\"\\nPhase 3: Function Version Validation\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            self.data_handler.preprocessor = pipeline_data['data_handler']['preprocessor']\n",
    "            self.data_handler.feature_generator = pipeline_data['data_handler']['feature_generator']\n",
    "            self.data_handler.features = pipeline_data['data_handler']['features']\n",
    "            \n",
    "            # Version validation\n",
    "            preprocessor_version = getattr(self.data_handler.preprocessor, 'version', 'unknown')\n",
    "            saved_preprocessor_version = pipeline_data['data_handler']['preprocessor_version']\n",
    "            if preprocessor_version != saved_preprocessor_version:\n",
    "                print(f\"⚠️ Warning: Current preprocessor version ({preprocessor_version}) \"\n",
    "                    f\"differs from saved version ({saved_preprocessor_version})\")\n",
    "            \n",
    "            feature_gen_version = getattr(self.data_handler.feature_generator, 'version', 'unknown')\n",
    "            saved_feature_gen_version = pipeline_data['data_handler']['feature_generator_version']\n",
    "            if feature_gen_version != saved_feature_gen_version:\n",
    "                print(f\"⚠️ Warning: Current feature generator version ({feature_gen_version}) \"\n",
    "                    f\"differs from saved version ({saved_feature_gen_version})\")\n",
    "            \n",
    "            # Phase 4: Data Handler Function Validation\n",
    "            print(\"\\nPhase 4: Data Handler Function Validation\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            # Validate preprocessor\n",
    "            if self.data_handler.preprocessor:\n",
    "                try:\n",
    "                    dummy_df = pl.DataFrame({\n",
    "                        'time_id': np.arange(5),\n",
    "                        'symbol_id': np.ones(5),\n",
    "                        'weight': np.ones(5),\n",
    "                        **{f'feature_{i:02d}': np.random.random(5) for i in range(79)}\n",
    "                    })\n",
    "                    processed_df = self.data_handler.preprocessor(dummy_df)\n",
    "                    if not isinstance(processed_df, pl.DataFrame):\n",
    "                        raise TypeError(f\"Preprocessor returned {type(processed_df)}, expected polars.DataFrame\")\n",
    "                    print(\"✓ Preprocessor function test passed\")\n",
    "                except Exception as e:\n",
    "                    raise RuntimeError(f\"Preprocessor function test failed: {str(e)}\")\n",
    "            \n",
    "            # Validate feature generator\n",
    "            if self.data_handler.feature_generator:\n",
    "                try:\n",
    "                    dummy_df = pl.DataFrame({\n",
    "                        'time_id': np.arange(5),\n",
    "                        'symbol_id': np.ones(5),\n",
    "                        'weight': np.ones(5),\n",
    "                        **{f'feature_{i:02d}': np.random.random(5) for i in range(79)}\n",
    "                    })\n",
    "                    generated_df = self.data_handler.feature_generator(dummy_df)\n",
    "                    if not isinstance(generated_df, pl.DataFrame):\n",
    "                        raise TypeError(f\"Feature generator returned {type(generated_df)}, expected polars.DataFrame\")\n",
    "                    print(\"✓ Feature generator function test passed\")\n",
    "                except Exception as e:\n",
    "                    raise RuntimeError(f\"Feature generator function test failed: {str(e)}\")\n",
    "            \n",
    "            # Validate features list\n",
    "            if not self.data_handler.features:\n",
    "                raise ValueError(\"Features list is empty\")\n",
    "            if not all(isinstance(f, str) for f in self.data_handler.features):\n",
    "                raise TypeError(\"All feature names must be strings\")\n",
    "            if len(self.data_handler.features) != len(set(self.data_handler.features)):\n",
    "                raise ValueError(\"Duplicate feature names found\")\n",
    "            print(\"✓ Features list validation passed\")\n",
    "            \n",
    "            # Phase 5: Pipeline Information\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"Pipeline Information:\")\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            print(f\"\\n1. Model Configuration:\")\n",
    "            print(f\"   - Model Type: {config_dict['model']['name']}\")\n",
    "            print(f\"   - Number of Features: {pipeline_data['data_handler']['n_features']}\")\n",
    "            print(f\"   - Model Parameters:\")\n",
    "            for k, v in config_dict['model']['params'].items():\n",
    "                print(f\"     * {k}: {v}\")\n",
    "            \n",
    "            print(f\"\\n2. Data Processing:\")\n",
    "            print(f\"   - Preprocessor: {self.data_handler.preprocessor.__name__ if self.data_handler.preprocessor else 'None'}\")\n",
    "            print(f\"     * Version: {saved_preprocessor_version}\")\n",
    "            print(f\"     * Description: {pipeline_data['data_handler']['preprocessor_description']}\")\n",
    "            print(f\"   - Feature Generator: {self.data_handler.feature_generator.__name__ if self.data_handler.feature_generator else 'None'}\")\n",
    "            print(f\"     * Version: {saved_feature_gen_version}\")\n",
    "            print(f\"     * Description: {pipeline_data['data_handler']['feature_generator_description']}\")\n",
    "            print(f\"   - First 5 Features: {self.data_handler.features[:5]}\")\n",
    "            \n",
    "            print(f\"\\n3. Split Strategy:\")\n",
    "            print(f\"   - Type: {config_dict['split_strategy']['type']}\")\n",
    "            for k, v in config_dict['split_strategy']['params'].items():\n",
    "                print(f\"   - {k}: {v}\")\n",
    "            \n",
    "            print(f\"\\n4. Load Location:\")\n",
    "            print(f\"   - Path: {load_path}\")\n",
    "            print(f\"   - Dataset Name: {config_dict['paths']['dataset_name']}\")\n",
    "            print(f\"   - Original Save Timestamp: {pipeline_data['timestamp']}\")\n",
    "            \n",
    "            # Final validation: Complete pipeline test\n",
    "            try:\n",
    "                dummy_features = {f: np.random.random(5) for f in self.data_handler.features}\n",
    "                dummy_df = pl.DataFrame({\n",
    "                    **dummy_features,\n",
    "                    'weight': np.ones(5)\n",
    "                })\n",
    "                X, _, _ = self.data_handler.get_feature_data(dummy_df)\n",
    "                final_pred = self.model.predict(X)\n",
    "                print(\"\\n✓ Complete pipeline test passed\")\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Complete pipeline test failed: {str(e)}\")\n",
    "            \n",
    "            print(\"\\nPipeline loaded and validated successfully! ✓\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError loading pipeline: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def upload_to_kaggle(self, dataset_title: Optional[str] = None):\n",
    "        \"\"\"Upload this pipeline to Kaggle dataset\"\"\"\n",
    "        self.kaggle_handler.upload_pipeline(self, dataset_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:07.184135Z",
     "start_time": "2024-11-09T08:09:07.177752Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    name: str = 'lightgbm'\n",
    "    params: Dict[str, Any] = None\n",
    "    custom_metrics: Dict[str, Callable] = field(default_factory=dict)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.params is None:\n",
    "            self.params = self.get_default_params()\n",
    "    \n",
    "    def get_default_params(self) -> Dict[str, Any]:\n",
    "        params = {\n",
    "            'lightgbm': {\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'verbosity': -1,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'learning_rate': 0.05,\n",
    "            },\n",
    "            'xgboost': {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'eval_metric': 'rmse',\n",
    "                'verbosity': 0,\n",
    "            },\n",
    "            # 'neural_network': {\n",
    "            #     'learning_rate': 0.001,\n",
    "            #     'batch_size': 512,\n",
    "            #     'epochs': 10,\n",
    "            # }\n",
    "        }\n",
    "        return params.get(self.name, {})\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Model\n",
    "    model: ModelConfig = ModelConfig()\n",
    "    # Paths\n",
    "    model_path: str = f\"{MODEL_PATH}/pipeline.pkl\"\n",
    "    dataset_name: str = \"jane-street-model\"\n",
    "    # Data loading\n",
    "    partition_range: Optional[List[int]] = None\n",
    "    # Training\n",
    "    split_strategy: SplitStrategy = field(default_factory=lambda: TimeBasedSplit(train_ratio=0.75, test_ratio=0.2))\n",
    "    seed: int = 42\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        np.random.seed(self.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduce memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:07.236079Z",
     "start_time": "2024-11-09T08:09:07.232365Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_memory(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Optimize data types for memory usage in Polars\"\"\"\n",
    "    start_mem = df.estimated_size() / (1024**2)\n",
    "    print(f'Memory usage of dataframe is {start_mem:.2f} MB')\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type in [pl.Float64, pl.Float32, pl.Int64, pl.Int32, pl.Int16, pl.Int8]:\n",
    "            c_min = df[col].drop_nulls().min()\n",
    "            c_max = df[col].drop_nulls().max()\n",
    "            \n",
    "            if c_min is not None and c_max is not None:  # null check 추가\n",
    "                if col_type in [pl.Int64, pl.Int32, pl.Int16, pl.Int8]:\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df = df.with_columns(pl.col(col).cast(pl.Int8))\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df = df.with_columns(pl.col(col).cast(pl.Int16))\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df = df.with_columns(pl.col(col).cast(pl.Int32))\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df = df.with_columns(pl.col(col).cast(pl.Float32))\n",
    "                    else:\n",
    "                        df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "        \n",
    "        elif col_type == pl.Utf8:\n",
    "            df = df.with_columns(pl.col(col).cast(pl.Categorical))\n",
    "    \n",
    "    end_mem = df.estimated_size() / (1024**2)\n",
    "    print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n",
    "    print(f'Decreased by {100 * (start_mem - end_mem) / start_mem:.1f}%')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:07.289165Z",
     "start_time": "2024-11-09T08:09:07.283261Z"
    }
   },
   "outputs": [],
   "source": [
    "@versioned_function(\"1.0.0\", \"Initial preprocessor with basic cleaning\")\n",
    "def default_preprocessor(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Default preprocessing function\"\"\"\n",
    "    df = reduce_memory(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:07.350365Z",
     "start_time": "2024-11-09T08:09:07.339564Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "@versioned_function(\"1.1.0\", \"Added time-based features and symbol_id processing\")\n",
    "def default_feature_generator(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Feature generation with time-based features\"\"\"\n",
    "    # Add time-based features using polars expressions\n",
    "    result = df.with_columns([\n",
    "        (2 * np.pi * pl.col('time_id') / 967).sin().alias('feature_sin_time_id'),\n",
    "        (2 * np.pi * pl.col('time_id') / 967).cos().alias('feature_cos_time_id'),\n",
    "        (2 * np.pi * pl.col('time_id') / 483).sin().alias('feature_sin_time_id_halfday'),\n",
    "        (2 * np.pi * pl.col('time_id') / 483).cos().alias('feature_cos_time_id_halfday')\n",
    "    ])\n",
    "\n",
    "    # Fill NA values and rename columns\n",
    "    result = (result\n",
    "    .fill_null(-1)\n",
    "    .rename({\n",
    "        'symbol_id': 'feature_symbol_id',\n",
    "        'weight': 'feature_weight'\n",
    "    }))\n",
    "\n",
    "    # Select and reorder columns\n",
    "    feature_cols = ['feature_symbol_id', 'feature_sin_time_id', 'feature_cos_time_id',\n",
    "                    'feature_sin_time_id_halfday', 'feature_cos_time_id_halfday', 'feature_weight']\n",
    "    feature_cols.extend([f'feature_0{i}' if i < 10 else f'feature_{i}'\n",
    "                         for i in range(79)])\n",
    "\n",
    "    # Add target column if it exists\n",
    "    if 'responder_6' in result.columns:\n",
    "        feature_cols.insert(0, 'responder_6')\n",
    "\n",
    "    return result.select(feature_cols) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:09:07.411154Z",
     "start_time": "2024-11-09T08:09:07.399846Z"
    }
   },
   "outputs": [],
   "source": [
    "lags_: pl.DataFrame | None = None\n",
    "\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame:\n",
    "    \"\"\"Competition prediction function\"\"\"\n",
    "    global pipeline\n",
    "    global lags_\n",
    "\n",
    "    row_ids = test['row_id'].to_numpy()\n",
    "\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "\n",
    "    if pipeline.data_handler.preprocessor:\n",
    "        test = pipeline.data_handler.preprocessor(test)\n",
    "    if pipeline.data_handler.feature_generator:\n",
    "        test = pipeline.data_handler.feature_generator(test)\n",
    "\n",
    "    predictions = pipeline.predict(test)\n",
    "    print(f\"Predictions shape: {predictions.shape}\")\n",
    "    print(f\"Predictions: {predictions}\")\n",
    "\n",
    "    result = pl.DataFrame({\n",
    "        'row_id': row_ids,\n",
    "        'responder_6': predictions\n",
    "    })\n",
    "    \n",
    "    # Validation checks\n",
    "    assert isinstance(result, (pl.DataFrame, pd.DataFrame))\n",
    "    assert result.columns == ['row_id', 'responder_6']\n",
    "    assert len(result) == len(test)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def run_inference_only(dataset_name: str, model_filename: str = 'pipeline.pkl') -> Pipeline:\n",
    "    \"\"\"Kaggle dataset에서 모델 로드하고 inference 준비\"\"\"\n",
    "    if not IS_KAGGLE:\n",
    "        raise ValueError(\"This function is for Kaggle environment only\")\n",
    "    \n",
    "    # Kaggle dataset에서 모델 파일 경로\n",
    "    model_path = f'/kaggle/input/{dataset_name}/{dataset_name}.pkl'\n",
    "    \n",
    "    # 파이프라인 초기화 및 모델 로드\n",
    "    pipeline = Pipeline(Config())\n",
    "    print(f\"Loading model from {model_path}\")\n",
    "    pipeline.load(model_path)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:15:07.182528Z",
     "start_time": "2024-11-09T08:09:07.462524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model locally...\n",
      "Loading and preparing data...\n",
      "Memory usage of dataframe is 16372.62 MB\n",
      "Memory usage after optimization is: 16058.01 MB\n",
      "Decreased by 1.9%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.01 MB\n",
      "Decreased by 6.0%\n",
      "Splitting data using configured strategy...\n",
      "\n",
      "Holdout Test Split Info:\n",
      "Total unique dates: 1699\n",
      "Train dates range: 0 - 1359\n",
      "Test dates range: 1360 - 1698\n",
      "Train samples: 34,712,738, Test samples: 12,414,600\n",
      "\n",
      "Time Series 5-Fold Split Info:\n",
      "Total unique dates: 1360\n",
      "Initial train size: 226 dates\n",
      "Validation size: ~226 dates per fold\n",
      "\n",
      "Fold 1:\n",
      "Train dates range: 0 - 225\n",
      "Val dates range: 226 - 451\n",
      "Train samples: 2,834,811, Val samples: 3,786,540\n",
      "\n",
      "Fold 2:\n",
      "Train dates range: 0 - 451\n",
      "Val dates range: 452 - 677\n",
      "Train samples: 6,621,351, Val samples: 5,124,619\n",
      "\n",
      "Fold 3:\n",
      "Train dates range: 0 - 677\n",
      "Val dates range: 678 - 903\n",
      "Train samples: 11,745,970, Val samples: 6,715,016\n",
      "\n",
      "Fold 4:\n",
      "Train dates range: 0 - 903\n",
      "Val dates range: 904 - 1129\n",
      "Train samples: 18,460,986, Val samples: 7,654,944\n",
      "\n",
      "Fold 5:\n",
      "Train dates range: 0 - 1129\n",
      "Val dates range: 1130 - 1359\n",
      "Train samples: 26,115,930, Val samples: 8,596,808\n",
      "\n",
      "Training fold 1/5\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.176742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18377\n",
      "[LightGBM] [Info] Number of data points in the train set: 2834811, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.002429\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's rmse: 0.927523\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's rmse: 0.926907\n",
      "Validation R2 score for fold 1: 0.0100\n",
      "\n",
      "Training fold 2/5\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.468737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19684\n",
      "[LightGBM] [Info] Number of data points in the train set: 6621351, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score -0.006536\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's rmse: 0.974124\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid's rmse: 0.974032\n",
      "Validation R2 score for fold 2: 0.0081\n",
      "\n",
      "Training fold 3/5\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.733890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20727\n",
      "[LightGBM] [Info] Number of data points in the train set: 11745970, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score -0.002795\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's rmse: 0.936895\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid's rmse: 0.936749\n",
      "Validation R2 score for fold 3: 0.0146\n",
      "\n",
      "Training fold 4/5\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.042523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18460986, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score -0.002524\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's rmse: 0.838219\n",
      "[200]\tvalid's rmse: 0.838069\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid's rmse: 0.838042\n",
      "Validation R2 score for fold 4: 0.0103\n",
      "\n",
      "Training fold 5/5\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.251126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20749\n",
      "[LightGBM] [Info] Number of data points in the train set: 26115930, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score -0.003538\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's rmse: 0.877763\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid's rmse: 0.877365\n",
      "Validation R2 score for fold 5: 0.0091\n",
      "\n",
      "Best validation score: 0.0146\n",
      "\n",
      "Saving pipeline...\n",
      "\n",
      "==================================================\n",
      "Pipeline Information:\n",
      "==================================================\n",
      "\n",
      "1. Model Configuration:\n",
      "   - Model Type: lightgbm\n",
      "   - Number of Features: 85\n",
      "   - Model Parameters:\n",
      "     * objective: regression_l2\n",
      "     * metric: rmse\n",
      "     * boosting_type: gbdt\n",
      "     * learning_rate: 0.1\n",
      "     * random_state: 42\n",
      "     * verbose: 1\n",
      "     * device: cpu\n",
      "\n",
      "2. Data Processing:\n",
      "   - Preprocessor: default_preprocessor\n",
      "     * Version: 1.0.0\n",
      "     * Description: Initial preprocessor with basic cleaning\n",
      "   - Feature Generator: default_feature_generator\n",
      "     * Version: 1.1.0\n",
      "     * Description: Added time-based features and symbol_id processing\n",
      "   - First 5 Features: ['feature_symbol_id', 'feature_sin_time_id', 'feature_cos_time_id', 'feature_sin_time_id_halfday', 'feature_cos_time_id_halfday']\n",
      "\n",
      "3. Split Strategy:\n",
      "   - Type: TimeSeriesKFold\n",
      "   - test_ratio: 0.2\n",
      "   - n_splits: 5\n",
      "\n",
      "4. Save Location:\n",
      "   - Path: ./models/pipeline.pkl\n",
      "   - Dataset Name: alvinlee9/jane-street-model-v1\n",
      "   - Timestamp: 2024-11-09 17:14:54\n",
      "\n",
      "Pipeline saved successfully! ✓\n",
      "Memory usage of dataframe is 16058.01 MB\n",
      "Memory usage after optimization is: 16058.01 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.01 MB\n",
      "Decreased by 0.0%\n",
      "\n",
      "Uploading pipeline to Kaggle...\n",
      "\n",
      "==================================================\n",
      "Pipeline Information:\n",
      "==================================================\n",
      "\n",
      "1. Model Configuration:\n",
      "   - Model Type: lightgbm\n",
      "   - Number of Features: 85\n",
      "   - Model Parameters:\n",
      "     * objective: regression_l2\n",
      "     * metric: rmse\n",
      "     * boosting_type: gbdt\n",
      "     * learning_rate: 0.1\n",
      "     * random_state: 42\n",
      "     * verbose: 1\n",
      "     * device: cpu\n",
      "\n",
      "2. Data Processing:\n",
      "   - Preprocessor: default_preprocessor\n",
      "     * Version: 1.0.0\n",
      "     * Description: Initial preprocessor with basic cleaning\n",
      "   - Feature Generator: default_feature_generator\n",
      "     * Version: 1.1.0\n",
      "     * Description: Added time-based features and symbol_id processing\n",
      "   - First 5 Features: ['feature_symbol_id', 'feature_sin_time_id', 'feature_cos_time_id', 'feature_sin_time_id_halfday', 'feature_cos_time_id_halfday']\n",
      "\n",
      "3. Split Strategy:\n",
      "   - Type: TimeSeriesKFold\n",
      "   - test_ratio: 0.2\n",
      "   - n_splits: 5\n",
      "\n",
      "4. Save Location:\n",
      "   - Path: ./models/jane-street-model-v1.pkl\n",
      "   - Dataset Name: alvinlee9/jane-street-model-v1\n",
      "   - Timestamp: 2024-11-09 17:14:58\n",
      "\n",
      "Pipeline saved successfully! ✓\n",
      "Creating new dataset: alvinlee9/jane-street-model-v1\n",
      "Starting upload for file jane-street-model-v1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258k/258k [00:01<00:00, 212kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: jane-street-model-v1.pkl (258KB)\n",
      "Dataset created successfully\n",
      "\n",
      "Evaluating on holdout test set...\n",
      "Starting prediction...\n",
      "Input DataFrame shape: (12414600, 86)\n",
      "Available features: ['feature_symbol_id', 'feature_sin_time_id', 'feature_cos_time_id', 'feature_sin_time_id_halfday', 'feature_cos_time_id_halfday', 'feature_weight', 'feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06', 'feature_07', 'feature_08', 'feature_09', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54', 'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76', 'feature_77', 'feature_78']\n",
      "Extracted feature matrix shape: (12414600, 85)\n",
      "Predictions shape: (12414600,)\n",
      "Holdout test R2 score: -0.0097\n",
      "\n",
      "Predicting on competition test set...\n",
      "Test data shape: (39, 85)\n",
      "Starting prediction...\n",
      "Input DataFrame shape: (39, 85)\n",
      "Available features: ['feature_symbol_id', 'feature_sin_time_id', 'feature_cos_time_id', 'feature_sin_time_id_halfday', 'feature_cos_time_id_halfday', 'feature_weight', 'feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06', 'feature_07', 'feature_08', 'feature_09', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54', 'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76', 'feature_77', 'feature_78']\n",
      "Extracted feature matrix shape: (39, 85)\n",
      "Predictions shape: (39,)\n",
      "Test predictions shape: (39,)\n",
      "[-0.0131654  -0.0131654  -0.0131654  -0.0131654  -0.05670995 -0.0131654\n",
      " -0.05670995 -0.0131654  -0.0131654  -0.05670995 -0.0131654  -0.05670995\n",
      " -0.0131654  -0.0131654  -0.05670995 -0.05670995 -0.0131654  -0.0131654\n",
      " -0.05670995 -0.0131654  -0.05670995 -0.05670995 -0.05670995 -0.05670995\n",
      " -0.05670995 -0.05670995 -0.05670995 -0.0131654  -0.05670995 -0.05670995\n",
      " -0.05670995 -0.05670995 -0.05670995 -0.05670995 -0.0131654  -0.05670995\n",
      " -0.06890116 -0.05670995 -0.0131654 ]\n"
     ]
    }
   ],
   "source": [
    "INFERENCE_ONLY = False  # True: inference만 실행, False: 학습 포함\n",
    "OPTIMIZE_HYPERPARAMS = False  # True: 하이퍼파라미터 최적화 실행\n",
    "NICKNAME = \"alvinlee9\"  # Kaggle nickname\n",
    "BASE_DATASET_NAME = \"jane-street-model-v1\"  # Base dataset name\n",
    "DATASET_NAME = f\"{BASE_DATASET_NAME}\" if IS_KAGGLE else f\"{NICKNAME}/{BASE_DATASET_NAME}\"\n",
    "\n",
    "if INFERENCE_ONLY and IS_KAGGLE:\n",
    "    # Inference only mode\n",
    "    print(\"Running in inference-only mode...\")\n",
    "    pipeline = run_inference_only(DATASET_NAME)\n",
    "else:\n",
    "    # Training mode\n",
    "    config = Config(\n",
    "        # partition_range=[6,7,8,9],\n",
    "        model=ModelConfig(\n",
    "            name='lightgbm',\n",
    "            params={\n",
    "                'objective': 'regression_l2',\n",
    "                'metric': 'rmse',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'learning_rate': 0.1,\n",
    "                'random_state': 42,\n",
    "                'verbose': 1,\n",
    "                'device': 'cpu',\n",
    "            },\n",
    "            custom_metrics={},\n",
    "        ),\n",
    "        dataset_name=DATASET_NAME,\n",
    "        split_strategy=TimeSeriesKFold(n_splits=5, test_ratio=0.2),\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(config)\n",
    "    \n",
    "    if not IS_KAGGLE:\n",
    "        # Local training\n",
    "        print(\"Training model locally...\")\n",
    "        holdout_test = pipeline.train(\n",
    "            preprocessor=default_preprocessor,\n",
    "            feature_generator=default_feature_generator,\n",
    "            optimize=OPTIMIZE_HYPERPARAMS,\n",
    "            n_trials=100 if OPTIMIZE_HYPERPARAMS else None\n",
    "        )\n",
    "\n",
    "        print(\"\\nUploading pipeline to Kaggle...\")\n",
    "        pipeline.upload_to_kaggle()\n",
    "\n",
    "        # Evaluate on holdout test set using R2\n",
    "        print(\"\\nEvaluating on holdout test set...\")\n",
    "        test_X, test_y, test_w = pipeline.data_handler.get_feature_data(holdout_test)\n",
    "        test_pred = pipeline.predict(holdout_test)\n",
    "        \n",
    "        # Calculate R2 score\n",
    "        _, r2_score, _ = r2_metric(test_y, test_pred, test_w)\n",
    "        print(f\"Holdout test R2 score: {r2_score:.4f}\")\n",
    "        \n",
    "        # Predict on competition test set if available\n",
    "        if pipeline.data_handler.test_data is not None:\n",
    "            print(\"\\nPredicting on competition test set...\")\n",
    "            test_data = pipeline.data_handler.test_data\n",
    "            print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "            test_pred = pipeline.predict(test_data)\n",
    "            print(f\"Test predictions shape: {test_pred.shape}\")\n",
    "            print(test_pred)\n",
    "    else:\n",
    "        # Kaggle training\n",
    "        print(\"Training model in Kaggle environment...\")\n",
    "        pipeline.train(\n",
    "            preprocessor=default_preprocessor,\n",
    "            feature_generator=default_feature_generator,\n",
    "            optimize=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:15:07.199901Z",
     "start_time": "2024-11-09T08:15:07.197567Z"
    }
   },
   "outputs": [],
   "source": [
    "if IS_KAGGLE:\n",
    "    import kaggle_evaluation.jane_street_inference_server\n",
    "\n",
    "    if not 'pipeline' in globals():  # pipeline이 아직 정의되지 않은 경우\n",
    "        # Inference only mode로 가정하고 모델 로드\n",
    "        pipeline = run_inference_only(DATASET_NAME)\n",
    "    \n",
    "    print(\"Setting up for competition submission...\")\n",
    "    inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(\n",
    "        predict\n",
    "    )\n",
    "    \n",
    "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "        print(\"Starting inference server...\")\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        print(\"Running local gateway...\")\n",
    "        inference_server.run_local_gateway(\n",
    "            (f'{BASE_PATH}/test.parquet', f'{BASE_PATH}/lags.parquet')\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Experiment Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T08:15:07.260734Z",
     "start_time": "2024-11-09T08:15:07.251333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Custom preprocessing and feature generation example\\ndef my_preprocessor(df: pl.DataFrame) -> pl.DataFrame:\\n    return df.with_columns([\\n        pl.col('weight').fill_null(pl.col('weight').mean()),\\n        pl.col('feature_00').clip(-3, 3),\\n        pl.col('feature_01').clip(-3, 3),\\n    ])\\n\\ndef my_feature_generator(df: pl.DataFrame) -> pl.DataFrame:\\n    return df.with_columns([\\n        # Moving statistics\\n        pl.col('feature_00').rolling_mean(window_size=10).alias('feature_00_ma10'),\\n        pl.col('feature_00').rolling_std(window_size=10).alias('feature_00_std10'),\\n        \\n        # Feature interactions\\n        (pl.col('feature_02') / (pl.col('feature_03') + 1e-7)).alias('feature_ratio_02_03'),\\n        \\n        # Group statistics\\n        pl.col('feature_00').mean().over('symbol_id').alias('feature_00_symbol_mean'),\\n    ])\\n\\n# Run custom experiment\\nconfig = Config(...)\\npipeline = Pipeline(config)\\npipeline.train(\\n    preprocessor=my_preprocessor,\\n    feature_generator=my_feature_generator,\\n    optimize=True\\n)\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Custom preprocessing and feature generation example\n",
    "def my_preprocessor(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return df.with_columns([\n",
    "        pl.col('weight').fill_null(pl.col('weight').mean()),\n",
    "        pl.col('feature_00').clip(-3, 3),\n",
    "        pl.col('feature_01').clip(-3, 3),\n",
    "    ])\n",
    "\n",
    "def my_feature_generator(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return df.with_columns([\n",
    "        # Moving statistics\n",
    "        pl.col('feature_00').rolling_mean(window_size=10).alias('feature_00_ma10'),\n",
    "        pl.col('feature_00').rolling_std(window_size=10).alias('feature_00_std10'),\n",
    "        \n",
    "        # Feature interactions\n",
    "        (pl.col('feature_02') / (pl.col('feature_03') + 1e-7)).alias('feature_ratio_02_03'),\n",
    "        \n",
    "        # Group statistics\n",
    "        pl.col('feature_00').mean().over('symbol_id').alias('feature_00_symbol_mean'),\n",
    "    ])\n",
    "\n",
    "# Run custom experiment\n",
    "config = Config(...)\n",
    "pipeline = Pipeline(config)\n",
    "pipeline.train(\n",
    "    preprocessor=my_preprocessor,\n",
    "    feature_generator=my_feature_generator,\n",
    "    optimize=True\n",
    ")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
